# Rekayasa Data

## Deskripsi

Mata kuliah ini membahas tentang rekayasa data (atau sering juga disebut sebagai *data  ngineering*), yaitu suatu disiplin pembelajaran untuk membuat suatu *data pipelines* dari *data sources* ditansofrmasikan ke dalam bentuk yang memudahkan analisis serta penyimpanan atau presentasi data tersebut  sampai ke *data consumer*. Disiplin ini memerlukan pengetahuan tentang sistem terdistribusi karena semua di era Cloud ini data bisa berasal dari mana saja. Mata kuliah ini menggunakan Apache Spark sebagai tools. Diharapkan, mahasiswa sudah memahami berbagai macam peranti pengembangan yang terkait - bisa Python, Java, Scala, maupun R - serta sistem terdistribusi dan *clustering*.

## Dosen

Dr. Bambang Purnomosidi D. P.

## Referensi

1.  [What is A Data Engineer?](https://www.dataquest.io/blog/what-is-a-data-engineer/).
2.  [Apache Spark Documentation](https://spark.apache.org/docs/latest/).
3.  [The Data Engineer's Guide to Apache Spark](https://databricks.com/p/ebook/data-engineer-spark-guide).
4.  [Learning Apache Spark with Python](https://runawayhorse001.github.io/LearningApacheSpark/pyspark.pdf) beserta supplement: [Notes on Apache Spark](https://github.com/MingChen0919/learning-apache-spark) dan [Learning Apache Spark](https://mingchen0919.github.io/learning-apache-spark/index.html).

## Materi

Semua materi sumber untuk kuliah disertakan disini, silahkan melihat referensi lain dari buku-buku maupun artikel. Referensi di atas juga mengandung berbagai pembahasan seperti yang ada di bawah ini, silahkan digunakan.

| Minggu | Materi | Sumber |
|-------:|--------|--------|
| 1 | Gambaran umum tentang rekayasa data | Ref-1 |
| 2 | Instalasi dan konfigurasi Apache Spark | [Download](https://spark.apache.org/downloads.html) untuk Apache Spark maupun PySpark, [Spark stand alone mode](https://spark.apache.org/docs/latest/spark-standalone.html) |
| 3 | Memulai Apache Spark | [dokumentasi](https://spark.apache.org/docs/latest/quick-start.html) |
| 4 | RDD (Resilient Distributed Dataset | [dokumentasi](https://spark.apache.org/docs/latest/rdd-programming-guide.html) |
| 5 | Spark SQL, DataFrames, dan Datasets | [dokumentasi](https://spark.apache.org/docs/latest/sql-programming-guide.html) |
| 6 | Structured streaming | [dokumentasi](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html) |
| 7 | Spark streaming | [dokumentasi](https://spark.apache.org/docs/latest/streaming-programming-guide.html) |
| 8 | Graph Data | [dokumentasi](https://spark.apache.org/docs/latest/graphx-programming-guide.html) |
| 9 | Lebih lanjut dengan PySpark | [dokumentasi](https://spark.apache.org/docs/latest/api/python/index.html) |
| 10 | Membangun *data pipeline* - 1 | [artikel](https://towardsdatascience.com/create-your-first-etl-pipeline-in-apache-spark-and-python-ec3d12e2c169) |
| 11 | Membangun *data pipeline* - 2: *streaming data pipeline* | [artikel](https://medium.com/@OpcitoTechnologies/building-a-real-time-data-pipeline-using-spark-streaming-and-kafka-a603495c4213) |
| 12 | Membangun *data pipeline* - 3: *real-time big data pipeline* | [artikel](https://adinasarapu.github.io/posts/2020/02/blog-post-spark/) |
| 13 | Kasus | dibahas di kelas |
| 14 | Kasus | dibahas di kelas |

